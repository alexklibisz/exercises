{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network from Scratch\n",
    "\n",
    "\n",
    "Implementation based on: http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-5/ and Andrew NG's Coursera Course weeks 4 and 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Functions that comprise the neural net.\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(z):\n",
    "    '''Vectorized sigmoid activation function.\n",
    "    Takes a numpy array of input/weight products and computes\n",
    "    the sigmoid activation over them. Formally:\n",
    "    \n",
    "                1\n",
    "    g(z) = -----------\n",
    "            1 + e^-z\n",
    "    \n",
    "    '''\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_derivative(z):\n",
    "    '''Computes the derivative of g(z), \n",
    "    g'(z) = g(z) .* (1-g(z))\n",
    "    '''\n",
    "    return np.multiply(sigmoid(z), (1 - sigmoid(z)))\n",
    "\n",
    "def forward_prop(X, Theta):\n",
    "    '''Forward propogation for a single X sample over a variable number of hidden layers.\n",
    "    Takes a single X sample and a list of theta matrices, one for each layer.\n",
    "    Assumes all nodes are connected and a single bias node in each layer.\n",
    "    '''\n",
    "    \n",
    "    L = len(Theta) + 1      # Number of layers including h(x).\n",
    "    Z = [None] * L          # Each Z[n] is the product (Theta[n] * A[n-1])\n",
    "    A = [None] * L          # Each A[n] is bias + sigmoid(Z[n])\n",
    "    bias = np.array([[1]])  # Bias will be prepended to each A[n].\n",
    "    \n",
    "    # Formality: Z[0] and A[0] are the input matrix.\n",
    "    Z[0] = X\n",
    "    A[0] = np.concatenate((bias, Z[0]))\n",
    "    \n",
    "    # Compute each of the layers.\n",
    "    for i in range(1,L):\n",
    "        Z[i] = np.dot(Theta[i-1], A[i-1])\n",
    "        A[i] = np.concatenate((bias, sigmoid(Z[i])))\n",
    "    \n",
    "    # Hypothesis is just the last activation without its bias.\n",
    "    h = A[-1][1:,:]\n",
    "    \n",
    "    return A, Z, h\n",
    "\n",
    "def forward_prop_multi(X, Theta):\n",
    "    '''Wrapper to evaluate forward_prop over multiple X samples\n",
    "    '''\n",
    "    A_multi = []\n",
    "    Z_multi = []\n",
    "    h_multi = []\n",
    "    for x in X:\n",
    "        A, Z, h = forward_prop(x, Theta)\n",
    "        A_multi.append(A)\n",
    "        Z_multi.append(Z)\n",
    "        h_multi.append(h)\n",
    "    return np.array(A_multi), np.array(Z_multi), np.array(h_multi)\n",
    "\n",
    "def reshape_weights(weights, layer_dims):\n",
    "    '''Creates Theta, a list of theta matrices that\n",
    "    should be applied for forward_prop.\n",
    "    Assumes len(layer_dims) = len(weights) + 1.\n",
    "    '''\n",
    "    # Reshape weights into Theta matrices.\n",
    "    # A layer with n nodes and 1 bias mapping to a layer with\n",
    "    # m nodes and 1 bias creates an (m by n + 1) matrix.\n",
    "    Theta = []\n",
    "    for i in range(len(weights)):\n",
    "        n = layer_dims[i]\n",
    "        m = layer_dims[i+1]\n",
    "        reshaped = np.reshape(weights[i], (m, n + 1))\n",
    "        Theta.append(reshaped)\n",
    "    return np.array(Theta)\n",
    "\n",
    "def compute_cost(X, y, Theta, learn_rate = 0.001):\n",
    "    '''Uses forward prop to evaluate the cost (J) of the given\n",
    "    Theta for all examples in X.  Evaluates forward_prop(X,Theta) \n",
    "    and computes the cost of the result relative y.\n",
    "    A vectorized implementation would probably be faster,\n",
    "    but arguably less readable.\n",
    "    '''\n",
    "    \n",
    "    L = Theta.shape[0] # Number of layers.\n",
    "    n = X.shape[0]     # Number of samples (e.g. 5000 images, n = 5000)\n",
    "    m = X.shape[1]     # Number of features (e.g. m = 400 pixels in a 20x20 image).\n",
    "    K = y.shape[1]     # Number of classes (e.g. 10 digits = 10)\n",
    "        \n",
    "    # Evaluate forward prop for all samples x in X.\n",
    "    _, _, h = forward_prop_multi(X, Theta)\n",
    "    \n",
    "    # Compute error summation.\n",
    "    print(y.shape)\n",
    "    print(h.shape)\n",
    "    errsum = 0\n",
    "    for i in range(m):\n",
    "        for k in range(K):\n",
    "            print('i = %d, k = %d' % (i,k))\n",
    "            print('y[%d][%d] = %lf' % (i, k, y[i][k]))\n",
    "            print('h[%d][%d] = %lf' % (i, k, y[i][k]))\n",
    "            errsum += y[i][k] * np.log(h[i][k]) + (1 - y[i][k]) * np.log(1 - (h[i][k]))\n",
    "    \n",
    "    # Compute regularization summation.\n",
    "    # Sum of all thetas except the bias node thetas.\n",
    "    # This means you leave out the 0th column.\n",
    "    regsum = 0\n",
    "    for t in Theta:\n",
    "        regsum += np.sum(t[:,1:])\n",
    "    \n",
    "    J = (-1 / m) * errsum + ((learn_rate / (2 * m)) * regsum)\n",
    "    \n",
    "    return J\n",
    "\n",
    "\n",
    "def back_prop(X, y, Theta, learn_rate = 0.001):\n",
    "    '''Back-propogation algorithm computes the parameter updates that will\n",
    "    reduce error on the training set. Implemented for a single (X,y) pair.\n",
    "    Returns the cost for this (X,y,Theta) combination and a gradient matrix\n",
    "    that indicates by how much to change the Theta for the next evaluation.\n",
    "    '''\n",
    "    \n",
    "    L = Theta.shape[0]\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # Evaluate forward prop for all samples in X.\n",
    "    A, Z, h = forward_prop(X, Theta)\n",
    "    \n",
    "    # Compute the hypothesis cost.\n",
    "    J = compute_cost(np.array([X]), np.array([y]), Theta, learn_rate)\n",
    "    \n",
    "    # Reverse iterate to compute delta and gradients.\n",
    "    grad = []           # Gradient at each layer.\n",
    "    Delta = [None] * L  # Delta at each layer.\n",
    "    \n",
    "    print(sigmoid(Z[-1]))\n",
    "    \n",
    "    # Last delta is just the difference of \n",
    "    Delta[-1] = h - y\n",
    "    Delta[1] = np.multiply(Theta[-1], Delta[-1]) * sigmoid_derivative(Z[-1])\n",
    "    \n",
    "    print(Delta)\n",
    "    \n",
    "    return J, grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEZCAYAAACAZ8KHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWSEOHGZmVogDh5mZFeLAYWZmhfx/wa8/tEBbZR8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff57dabf668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward prop hypothesis =  [[ 0.87824242]]\n",
      "(3, 1)\n",
      "(3, 1, 1)\n",
      "y[0][0] = 1.000000\n",
      "h[0][0] = 1.000000\n",
      "y[1][0] = 0.000000\n",
      "h[1][0] = 0.000000\n",
      "y[2][0] = 1.000000\n",
      "h[2][0] = 1.000000\n",
      "Computed cost = 0.791240\n",
      "(1, 1, 1)\n",
      "(1, 1, 1)\n",
      "y[0][0] = 1.000000\n",
      "h[0][0] = 1.000000\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-281-fdbfc9863cc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mback_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Computed gradient = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-280-47f14f647183>\u001b[0m in \u001b[0;36mback_prop\u001b[0;34m(X, y, Theta, learn_rate)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;31m# Compute the hypothesis cost.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mJ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;31m# Reverse iterate to compute delta and gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-280-47f14f647183>\u001b[0m in \u001b[0;36mcompute_cost\u001b[0;34m(X, y, Theta, learn_rate)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y[%d][%d] = %lf'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'h[%d][%d] = %lf'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0merrsum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "# Function examples\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Sigmoid activation function example\n",
    "z = np.random.rand(100,1) * 100 % 20 -10\n",
    "g = sigmoid(z)\n",
    "plt.title('Sigmoid activation example')\n",
    "plt.xlabel('Random value in [%d, %d]' % (floor(min(z)), ceil(max(z))))\n",
    "plt.ylabel('Activation output')\n",
    "plt.plot(z, g, 'b.')\n",
    "plt.xlim(-10,10)\n",
    "plt.ylim(-0.2,1.2)\n",
    "plt.show()\n",
    "\n",
    "# Forward propogation and reshape function example.\n",
    "# Follows the example from coursera machine learning week 3.\n",
    "# 3 inputs, one hidden-layer with 3 nodes, one output node.\n",
    "X = np.matrix([[0.3], [0.4], [0.5]]) # 3 X inputs as a column vector.\n",
    "layer_dims = [\n",
    "    3, # Layer 0 has 3 nodes.\n",
    "    3, # Layer 1 has 3 nodes.\n",
    "    1, # Layer 2 has 1 node.\n",
    "    1, # Hypothesis is 1 node.\n",
    "]\n",
    "weights = np.array([\n",
    "    np.ones(12), # (3 nodes, 1 bias) -> (3 nodes)\n",
    "    np.ones(4),  # (3 nodes, 1 bias) -> (1 node)\n",
    "    np.ones(2),  # (1 node, 1 bias) -> (1 node)\n",
    "])\n",
    "Theta = reshape_weights(weights, layer_dims)\n",
    "A, Z, h = forward_prop(X, Theta)\n",
    "print('Forward prop hypothesis = ', h)\n",
    "\n",
    "# Cost function example.\n",
    "# Same as above, assume that the correct hypothesis is 1 \n",
    "# (e.g. True in binary classification).\n",
    "X_multi = np.array([\n",
    "    X + 0.1,\n",
    "    X + 0.2,\n",
    "    X + 0.3\n",
    "])\n",
    "y_multi = np.array([\n",
    "    np.array([1]),\n",
    "    np.array([0]),\n",
    "    np.array([1])\n",
    "])\n",
    "cost = compute_cost(X_multi, y_multi, Theta)\n",
    "print('Computed cost = %lf' % cost)\n",
    "\n",
    "# Back propogation function example.\n",
    "# Should work for a single X, y pair with Theta for all layers.\n",
    "X = np.matrix([[0.3], [0.4], [0.5]])\n",
    "y = np.array([np.array([1])])\n",
    "cost, gradient = back_prop(X, y, Theta)\n",
    "print('Computed gradient = ', gradient)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs (X): 5000 images, 400 pixels (unfolded)\n",
      "Labels (y): 5000 labels, 10 unique\n",
      "Labels onehot-encoded 5000 x 10\n"
     ]
    }
   ],
   "source": [
    "# Reading data and using the neural net.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "%matplotlib inline\n",
    "\n",
    "# Read data into X and y vectors.\n",
    "data = loadmat('data/ex3data1.mat')\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "\n",
    "# Understand the data dimensions.\n",
    "print('Inputs (X): %d images, %d pixels (unfolded)' % (X.shape[0], X.shape[1]))\n",
    "print('Labels (y): %d labels, %d unique' % (y.shape[0], len(np.unique(y))))\n",
    "\n",
    "# Onehot-encoding turns y into a matrix where\n",
    "# each row has a 1 in the position corresponding\n",
    "# to the label, 0s everywhere else.\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_onehot = encoder.fit_transform(y)\n",
    "print('Labels onehot-encoded %d x %d' % y_onehot.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "[[ 1.  1.]\n",
      " [ 1.  1.]\n",
      " [ 1.  1.]\n",
      " [ 1.  1.]\n",
      " [ 1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# Scratch area\n",
    "import numpy as np\n",
    "\n",
    "a = np.ones(10)\n",
    "b = np.reshape(a, (5,2))\n",
    "print(a)\n",
    "print(b)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
