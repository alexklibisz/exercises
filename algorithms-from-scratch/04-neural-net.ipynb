{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network from Scratch\n",
    "\n",
    "\n",
    "Implementation based on: http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-5/ and Andrew NG's Coursera Course weeks 4 and 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Functions that comprise the neural net.\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(z):\n",
    "    '''Vectorized sigmoid activation function.\n",
    "    Takes a numpy array of input/weight products and computes\n",
    "    the sigmoid activation over them. Formally:\n",
    "    \n",
    "                1\n",
    "    g(z) = -----------\n",
    "            1 + e^-z\n",
    "    \n",
    "    '''\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_derivative(z):\n",
    "    '''Computes the derivative of g(z), \n",
    "    g'(z) = g(z) .* (1-g(z))\n",
    "    '''\n",
    "    return np.multiply(sigmoid(z), (1 - sigmoid(z)))\n",
    "\n",
    "def forward_prop(X, Theta):\n",
    "    '''Forward propogation for a single X sample over a variable number of hidden layers.\n",
    "    Takes a single X sample and a list of theta matrices, one for each layer.\n",
    "    Assumes all nodes are connected and a single bias node in each layer.\n",
    "    '''\n",
    "    \n",
    "    L = len(Theta) + 1      # Number of layers including h(x).\n",
    "    Z = [None] * L          # Each Z[n] is the product (Theta[n] * A[n-1])\n",
    "    A = [None] * L          # Each A[n] is bias + sigmoid(Z[n])\n",
    "    bias = np.array([[1]])  # Bias will be prepended to each A[n].\n",
    "    \n",
    "    # Formality: Z[0] and A[0] are the input matrix.\n",
    "    Z[0] = X\n",
    "    A[0] = np.concatenate((bias, Z[0]))\n",
    "    \n",
    "    # Compute each of the layers.\n",
    "    for i in range(1,L):\n",
    "        Z[i] = np.dot(Theta[i-1], A[i-1])\n",
    "        A[i] = np.concatenate((bias, sigmoid(Z[i])))\n",
    "    \n",
    "    # Hypothesis is just the last activation without its bias.\n",
    "    h = A[-1][1:,:]\n",
    "    \n",
    "    return A, Z, h\n",
    "\n",
    "def forward_prop_multi(X, Theta):\n",
    "    '''Wrapper to evaluate forward_prop over multiple X samples\n",
    "    '''\n",
    "    A_multi = []\n",
    "    Z_multi = []\n",
    "    h_multi = []\n",
    "    for x in X:\n",
    "        A, Z, h = forward_prop(x, Theta)\n",
    "        A_multi.append(A)\n",
    "        Z_multi.append(Z)\n",
    "        h_multi.append(h)\n",
    "    return np.array(A_multi), np.array(Z_multi), np.array(h_multi)\n",
    "\n",
    "def reshape_weights(weights, layer_dims):\n",
    "    '''Creates Theta, a list of theta matrices that\n",
    "    should be applied for forward_prop.\n",
    "    Assumes len(layer_dims) = len(weights) + 1.\n",
    "    '''\n",
    "    # Reshape weights into Theta matrices.\n",
    "    # A layer with n nodes and 1 bias mapping to a layer with\n",
    "    # m nodes and 1 bias creates an (m by n + 1) matrix.\n",
    "    Theta = []\n",
    "    for i in range(len(weights)):\n",
    "        n = layer_dims[i]\n",
    "        m = layer_dims[i+1]\n",
    "        reshaped = np.reshape(weights[i], (m, n + 1))\n",
    "        Theta.append(reshaped)\n",
    "    return np.array(Theta)\n",
    "\n",
    "def compute_cost(X, y, Theta, learn_rate = 0.001):\n",
    "    '''Uses forward prop to evaluate the cost (J) of the given\n",
    "    Theta for all examples in X.  Evaluates forward_prop(X,Theta) \n",
    "    and computes the cost of the result relative y.\n",
    "    A vectorized implementation would probably be faster,\n",
    "    but arguably less readable.\n",
    "    '''\n",
    "    \n",
    "    L = Theta.shape[0] # Number of layers.\n",
    "    n = X.shape[0]     # Number of samples (e.g. 5000 images, n = 5000)\n",
    "    m = X.shape[1]     # Number of features (e.g. m = 400 pixels in a 20x20 image).\n",
    "    K = y.shape[1]     # Number of classes (e.g. 10 digits = 10)\n",
    "        \n",
    "    # Evaluate forward prop for all samples x in X.\n",
    "    _, _, h = forward_prop_multi(X, Theta)\n",
    "    \n",
    "    # Compute error summation.\n",
    "    print(y.shape)\n",
    "    print(h.shape)\n",
    "    errsum = 0\n",
    "    for i in range(m):\n",
    "        for k in range(K):\n",
    "            print('i = %d, k = %d' % (i,k))\n",
    "            print('y[%d][%d] = %lf' % (i, k, y[i][k]))\n",
    "            print('h[%d][%d] = %lf' % (i, k, y[i][k]))\n",
    "            errsum += y[i][k] * np.log(h[i][k]) + (1 - y[i][k]) * np.log(1 - (h[i][k]))\n",
    "    \n",
    "    # Compute regularization summation.\n",
    "    # Sum of all thetas except the bias node thetas.\n",
    "    # This means you leave out the 0th column.\n",
    "    regsum = 0\n",
    "    for t in Theta:\n",
    "        regsum += np.sum(t[:,1:])\n",
    "    \n",
    "    J = (-1 / m) * errsum + ((learn_rate / (2 * m)) * regsum)\n",
    "    \n",
    "    return J\n",
    "\n",
    "\n",
    "def back_prop(X, y, Theta, learn_rate = 0.001):\n",
    "    '''Back-propogation algorithm computes the parameter updates that will\n",
    "    reduce error on the training set. Implemented for a single (X,y) pair.\n",
    "    Returns the cost for this (X,y,Theta) combination and a gradient matrix\n",
    "    that indicates by how much to change the Theta for the next evaluation.\n",
    "    '''\n",
    "    \n",
    "    L = Theta.shape[0]\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # Evaluate forward prop for all samples in X.\n",
    "    A, Z, h = forward_prop(X, Theta)\n",
    "    \n",
    "    # Compute the hypothesis cost.\n",
    "    J = compute_cost(np.array([X]), np.array([y]), Theta, learn_rate)\n",
    "    \n",
    "    # Reverse iterate to compute delta and gradients.\n",
    "    grad = []           # Gradient at each layer.\n",
    "    Delta = [None] * L  # Delta at each layer.\n",
    "    \n",
    "    print(sigmoid(Z[-1]))\n",
    "    \n",
    "    # Last delta is just the difference of \n",
    "    Delta[-1] = h - y\n",
    "    Delta[1] = np.multiply(Theta[-1], Delta[-1]) * sigmoid_derivative(Z[-1])\n",
    "    \n",
    "    print(Delta)\n",
    "    \n",
    "    return J, grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEZCAYAAACAZ8KHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff57d85b0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward prop hypothesis =  [[ 0.87824242]]\n",
      "(3, 1)\n",
      "(3, 1, 1)\n",
      "i = 0, k = 0\n",
      "y[0][0] = 1.000000\n",
      "h[0][0] = 1.000000\n",
      "i = 1, k = 0\n",
      "y[1][0] = 0.000000\n",
      "h[1][0] = 0.000000\n",
      "i = 2, k = 0\n",
      "y[2][0] = 1.000000\n",
      "h[2][0] = 1.000000\n",
      "Computed cost = 0.791240\n",
      "(1, 1, 1)\n",
      "(1, 1, 1)\n",
      "i = 0, k = 0\n",
      "y[0][0] = 1.000000\n",
      "h[0][0] = 1.000000\n",
      "i = 1, k = 0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-284-fdbfc9863cc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mback_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Computed gradient = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-283-ea576bf10f4f>\u001b[0m in \u001b[0;36mback_prop\u001b[0;34m(X, y, Theta, learn_rate)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;31m# Compute the hypothesis cost.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0mJ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;31m# Reverse iterate to compute delta and gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-283-ea576bf10f4f>\u001b[0m in \u001b[0;36mcompute_cost\u001b[0;34m(X, y, Theta, learn_rate)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i = %d, k = %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y[%d][%d] = %lf'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'h[%d][%d] = %lf'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0merrsum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "# Function examples\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Sigmoid activation function example\n",
    "z = np.random.rand(100,1) * 100 % 20 -10\n",
    "g = sigmoid(z)\n",
    "plt.title('Sigmoid activation example')\n",
    "plt.xlabel('Random value in [%d, %d]' % (floor(min(z)), ceil(max(z))))\n",
    "plt.ylabel('Activation output')\n",
    "plt.plot(z, g, 'b.')\n",
    "plt.xlim(-10,10)\n",
    "plt.ylim(-0.2,1.2)\n",
    "plt.show()\n",
    "\n",
    "# Forward propogation and reshape function example.\n",
    "# Follows the example from coursera machine learning week 3.\n",
    "# 3 inputs, one hidden-layer with 3 nodes, one output node.\n",
    "X = np.matrix([[0.3], [0.4], [0.5]]) # 3 X inputs as a column vector.\n",
    "layer_dims = [\n",
    "    3, # Layer 0 has 3 nodes.\n",
    "    3, # Layer 1 has 3 nodes.\n",
    "    1, # Layer 2 has 1 node.\n",
    "    1, # Hypothesis is 1 node.\n",
    "]\n",
    "weights = np.array([\n",
    "    np.ones(12), # (3 nodes, 1 bias) -> (3 nodes)\n",
    "    np.ones(4),  # (3 nodes, 1 bias) -> (1 node)\n",
    "    np.ones(2),  # (1 node, 1 bias) -> (1 node)\n",
    "])\n",
    "Theta = reshape_weights(weights, layer_dims)\n",
    "A, Z, h = forward_prop(X, Theta)\n",
    "print('Forward prop hypothesis = ', h)\n",
    "\n",
    "# Cost function example.\n",
    "# Same as above, assume that the correct hypothesis is 1 \n",
    "# (e.g. True in binary classification).\n",
    "X_multi = np.array([\n",
    "    X + 0.1,\n",
    "    X + 0.2,\n",
    "    X + 0.3\n",
    "])\n",
    "y_multi = np.array([\n",
    "    np.array([1]),\n",
    "    np.array([0]),\n",
    "    np.array([1])\n",
    "])\n",
    "cost = compute_cost(X_multi, y_multi, Theta)\n",
    "print('Computed cost = %lf' % cost)\n",
    "\n",
    "# Back propogation function example.\n",
    "# Should work for a single X, y pair with Theta for all layers.\n",
    "X = np.matrix([[0.3], [0.4], [0.5]])\n",
    "y = np.array([np.array([1])])\n",
    "cost, gradient = back_prop(X, y, Theta)\n",
    "print('Computed gradient = ', gradient)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs (X): 5000 images, 400 pixels (unfolded)\n",
      "Labels (y): 5000 labels, 10 unique\n",
      "Labels onehot-encoded 5000 x 10\n"
     ]
    }
   ],
   "source": [
    "# Reading data and using the neural net.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "%matplotlib inline\n",
    "\n",
    "# Read data into X and y vectors.\n",
    "data = loadmat('data/ex3data1.mat')\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "\n",
    "# Understand the data dimensions.\n",
    "print('Inputs (X): %d images, %d pixels (unfolded)' % (X.shape[0], X.shape[1]))\n",
    "print('Labels (y): %d labels, %d unique' % (y.shape[0], len(np.unique(y))))\n",
    "\n",
    "# Onehot-encoding turns y into a matrix where\n",
    "# each row has a 1 in the position corresponding\n",
    "# to the label, 0s everywhere else.\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_onehot = encoder.fit_transform(y)\n",
    "print('Labels onehot-encoded %d x %d' % y_onehot.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "[[ 1.  1.]\n",
      " [ 1.  1.]\n",
      " [ 1.  1.]\n",
      " [ 1.  1.]\n",
      " [ 1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# Scratch area\n",
    "import numpy as np\n",
    "\n",
    "a = np.ones(10)\n",
    "b = np.reshape(a, (5,2))\n",
    "print(a)\n",
    "print(b)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
