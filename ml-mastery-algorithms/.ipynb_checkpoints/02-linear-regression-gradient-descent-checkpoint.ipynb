{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with Gradient Descent\n",
    "\n",
    "Practicing linear regression with gradient descent implemented from scratch.\n",
    "\n",
    "Data taken from UCI Auto MPG dataset: https://archive.ics.uci.edu/ml/datasets/Auto+MPG\n",
    "\n",
    "Using **auto weight** to predict **mpg**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Gradient Descent\n",
    "\n",
    "Following the videos in on Coursera (http://coursera.org/learn/machine-learning/) week two and this stack overflow question: http://stackoverflow.com/questions/17784587.\n",
    "\n",
    "Used the sklearn preprocessing library to scale the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class MyGradientDescent():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._theta = None\n",
    "        \n",
    "    def fit(self, x, y, alpha = 0.0005, numIter = 10000, verbose=False):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        x: m by n numpy feature matrix, one row per sample\n",
    "        y: m by 1 numpy response variable column vector, one row per sample\n",
    "        alpha: learning rate\n",
    "        numIter: max number of iterations to run\n",
    "        verbose: if True, this function will print the mse every 100 iterations\n",
    "        '''\n",
    "    \n",
    "        # m is the number of samples.\n",
    "        # n is the number of features.\n",
    "        m, n = x.shape\n",
    "\n",
    "        # Copy, scale, and prepend x and theta with a column of ones.\n",
    "        # Explained here: http://stats.stackexchange.com/questions/181603\n",
    "        x = x.copy()\n",
    "        x = self._scale(x)\n",
    "        x = np.column_stack((np.ones(shape=(m,1)),x))\n",
    "        self._theta = np.ones(n + 1)\n",
    "        \n",
    "        # Transpose for multiplication. xT is n * m.\n",
    "        xT = x.transpose()\n",
    "\n",
    "        for i in range(0, numIter):\n",
    "\n",
    "            # Get the current hypothesis by multiplying the feature matrix by the theta weights.\n",
    "            # x dot theta is (m by n) * (n by 1)\n",
    "            hypothesis = np.dot(x, self._theta)\n",
    "\n",
    "            # Calculate the error from this hypothesis.\n",
    "            # This is vectorized, error will be (m by 1)\n",
    "            error = hypothesis - y\n",
    "            \n",
    "            # Get mean squared error, helpful for printing for each iteration.\n",
    "            if verbose:\n",
    "                if i % 100 == 0:\n",
    "                    mse = mean_squared_error(hypothesis, y)\n",
    "                    print('iteration %d | mse %f' % (i, mse))\n",
    "\n",
    "            # Calculate the gradient, gradient will be (m by 1).\n",
    "            gradient = (1/m) * np.dot(xT, error)\n",
    "\n",
    "            # Update the weights based on the gradient.\n",
    "            self._theta = self._theta - (alpha * gradient)\n",
    "        \n",
    "        return self._theta\n",
    "    \n",
    "    def predict(self, x):\n",
    "        m, n = x.shape\n",
    "        ones = np.ones(shape=(m,1))\n",
    "        x_scaled = self._scale(x)\n",
    "        x_ones = np.column_stack((ones,x_scaled))\n",
    "        return np.dot(x_ones, self._theta)\n",
    "    \n",
    "    def _mse(self, A, B):\n",
    "        return np.sum((A - B) ** 2) / A.shape[0]\n",
    "    \n",
    "    def _scale(self, A):\n",
    "        return (A - np.mean(A)) / np.std(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "Using weight as the feature and mpg as the dependent variable.\n",
    "\n",
    "It's important to center this data (mean of 0, stddev of 1). If you don't center the data, the linear regression will not converge - at least not with the parameters set here. You'll see that the MyLinearRegression class takes care of the centering, as does the Scikit-Learn LinearRegression class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEZCAYAAABiu9n+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nELn8f7dLMNVc/4JSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9decd3ce80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "names = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin', 'name']\n",
    "df = pd.read_csv('./data/auto-mpg.data', names=names, header=None, delim_whitespace=True)\n",
    "\n",
    "x = df[['weight']].values\n",
    "y = df['mpg'].values\n",
    "\n",
    "plt.title('Loaded Data')\n",
    "plt.xlabel('weight')\n",
    "plt.ylabel('mpg')\n",
    "plt.plot(x, y, 'r.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict a Line of Best Fit\n",
    "\n",
    "Note - there is no test/train split here, just fitting a line through all the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-607207869668>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyGradientDescent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumIter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-4ab180f8f80b>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mx_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mx_ones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_ones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_theta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocessing' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model = MyGradientDescent()\n",
    "model.fit(x, y, verbose=False, numIter=20000)\n",
    "predicted = model.predict(x)\n",
    "mse = mean_squared_error(predicted,y)\n",
    "\n",
    "plt.title('Data with LOBF')\n",
    "plt.plot(x, y, 'b.')\n",
    "plt.plot(x, predicted, 'r.')\n",
    "plt.show()\n",
    "\n",
    "print('mse = %lf' % (mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to Scikit-Learn Implementation\n",
    "\n",
    "Scikit learn has a solid LinearRegression implementation. Let's compare the mean squared error.\n",
    "\n",
    "They both evaluate to a mean squared error ~18.78."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x,y)\n",
    "\n",
    "predicted = model.predict(x)\n",
    "mse = mean_squared_error(predicted, y)\n",
    "\n",
    "plt.title('Data with LOBF (Scikit Learn Implementation)')\n",
    "plt.plot(x, y, 'b.')\n",
    "plt.plot(x, predicted, 'r.')\n",
    "plt.show()\n",
    "\n",
    "print('mse = %lf' % (mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch Code\n",
    "\n",
    "Disregard the code below. This was a prior implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def gradientDescent(x, y, alpha, numIter):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    x: m by n numpy feature matrix, one row per sample\n",
    "    y: m by 1 numpy response variable column vector, one row per sample\n",
    "    theta: n by 1 feature weights\n",
    "    alpha: learning rate\n",
    "    numIter: max number of iterations to run\n",
    "    \n",
    "    '''\n",
    "    # m is the number of samples.\n",
    "    # n is the number of features.\n",
    "    m, n = x.shape\n",
    "    \n",
    "    # Make a copy of x and prepend x and theta with a column of ones.\n",
    "    # Explained here: http://stats.stackexchange.com/questions/181603\n",
    "    x = x.copy()\n",
    "    x = np.column_stack((np.ones(shape=(m,1)),x))\n",
    "    theta = np.ones(n + 1)\n",
    "    \n",
    "    \n",
    "    # Transpose for multiplication. xT is n * m.\n",
    "    xT = x.transpose()\n",
    "    \n",
    "    for i in range(0, numIter):\n",
    "        \n",
    "        # Get the current hypothesis by multiplying the feature matrix by the theta weights.\n",
    "        # x dot theta is (m by n) * (n by 1)\n",
    "        hypothesis = np.dot(x, theta)\n",
    "                \n",
    "        # Calculate the error from this hypothesis.\n",
    "        # This is vectorized, error will be (m by 1)\n",
    "        error = hypothesis - y\n",
    "        \n",
    "        # Get mean squared error, helpful for printing for each iteration.\n",
    "        # if i % 100 == 0:\n",
    "            # meanSquaredError = np.sum(error ** 2) / (2*m)\n",
    "            # print('iteration %d | cost %f' % (i, meanSquaredError))\n",
    "        \n",
    "        # Calculate the gradient, gradient will be (m by 1).\n",
    "        gradient = (1/m) * np.dot(xT, error)\n",
    "        \n",
    "        # Update the weights based on the gradient.\n",
    "        theta = theta - (alpha * gradient)\n",
    "    \n",
    "    # Return the last m columns.\n",
    "    return theta\n",
    "\n",
    "def predict(x, theta):\n",
    "    # x gets copied and pre-prended with a column of ones.\n",
    "    x = x.copy()\n",
    "    x = np.column_stack((np.ones(shape=(m,1)),x))\n",
    "    prediction = np.dot(x,theta)\n",
    "    return prediction\n",
    "    \n",
    "\n",
    "def randomData(numSamples, numFeatures, bias, variance):\n",
    "    x = np.zeros(shape=(numSamples, numFeatures))\n",
    "    y = np.zeros(shape=numSamples)\n",
    "    # basically a straight line\n",
    "    for i in range(0, numSamples):\n",
    "        for j in range(0, numFeatures):\n",
    "            dist = random.uniform(0,20)\n",
    "            x[i][j] = i + random.uniform(-dist,dist)\n",
    "        # Target variable\n",
    "        y[i] = (i + bias) + random.uniform(0, 1) * variance\n",
    "    return x, y\n",
    "\n",
    "x, y = randomData(100, 1, 25, 20)\n",
    "m, n = np.shape(x)\n",
    "alpha = 0.0005\n",
    "numIter = 10000\n",
    "\n",
    "# Get the weights.\n",
    "theta = gradientDescent(x, y, alpha, numIter)\n",
    "predicted = predict(x, theta)\n",
    "\n",
    "# Plot\n",
    "plt.plot(x,y, 'b*')\n",
    "plt.plot(x,predicted,'r')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
