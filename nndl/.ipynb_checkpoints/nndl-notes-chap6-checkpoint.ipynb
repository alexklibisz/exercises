{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks and Deep Learning Notes\n",
    "\n",
    "Notes and equations from [neuralnetworksanddeeplearning.com](http://neuralnetworksanddeeplearning.com/)\n",
    "\n",
    "# Chapter 4\n",
    "\n",
    "## Overview\n",
    "\n",
    "1. Convolutional neural networks.\n",
    "2. Review of recent work with conv nets.\n",
    "3. Recurrent and LSTM models.\n",
    "4. Speculation on future work in neural networks.\n",
    "\n",
    "## Introducing convolutional networks\n",
    "\n",
    "- Networks with fully connected layers do not take into account the spatial structure of an image.\n",
    "- \"It treats input pixels which are far apart and close together on exactly the same footing.\"\n",
    "- Three basic ideas: **local receptive fields**, **shared weights**, **pooling**.\n",
    "\n",
    "### Local receptive fields\n",
    "\n",
    "- Think of the MNIST inputs as a 28x28 square of neurons with values corresponding to the pixel intensities from the image.\n",
    "- Connections to hidden layers are only made in small, localized regions of the input image.\n",
    "- A hidden neuron's **local receptive field** is the field of inputs that are connected to it.\n",
    "\n",
    "![](http://neuralnetworksanddeeplearning.com/images/tikz43.png)\n",
    "\n",
    "- The LRF is slid across the image, connecting to a different neuron at each movement:\n",
    "\n",
    "![](http://neuralnetworksanddeeplearning.com/images/tikz44.png)\n",
    "\n",
    "![](http://neuralnetworksanddeeplearning.com/images/tikz45.png)\n",
    "\n",
    "- The number of neurons in the hidden layer depends on the size of the receptive field. A 28x28 input with a 5x5 LRP would connect to a 24x24 hidden layer.\n",
    "- The LRP stride length can vary - e.g. move 2 pixels for every connection.\n",
    "\n",
    "### Shared weights (and biases)\n",
    "\n",
    "- All of the neurons in the 24x24 layer use the same weights and bias.\n",
    "\n",
    "$\\begin{eqnarray} \n",
    "  \\sigma\\left(b + \\sum_{l=0}^4 \\sum_{m=0}^4  w_{l,m} a_{j+l, k+m} \\right).\n",
    "\\tag{125}\\end{eqnarray}$\n",
    "\n",
    "- $w_{l,m}$ is a 5x5 array of shared weights, $b$ is a shared bias.\n",
    "- All of the neurons in the first hidden layer detect exactly the same feature (e.g. an edge) across different locations of the image.\n",
    "- This makes CNNs good for handling translated images - a picture of a cat shifted slightly is still a picture of a cat.\n",
    "- To do image recognition, you need to be able to detect more than one type of feature. So a CNN combines multiple feature maps into each hidden layer:\n",
    "\n",
    "![](http://neuralnetworksanddeeplearning.com/images/tikz46.png)\n",
    "\n",
    "- Shared weights decrease the number of parameters in the network. A 24x24 feature map with 5x5 local receptive fields will have 25 weights + 1 bias = 26 parameters. Whereas a 30 neuron fully-connected layer will have 784x30 weights + 30 biases = 23,550 parameters.\n",
    "\n",
    "### Pooling layers\n",
    "\n",
    "- Pooling layers come after convolutional layers. They condense the multiple feature maps from a convolutional layer into a single simpler feature map.\n",
    "- Each neuron in a pooling layer takes inputs from a specific section of the feature maps in the prior convolutional layer (e.g. a 2x2 section in the convolutional feature maps maps to a single neuron in the pooling layer).\n",
    "\n",
    "![](http://neuralnetworksanddeeplearning.com/images/tikz47.png)\n",
    "\n",
    "- Example: **max-pooling** layers take the max of each input segment.\n",
    "- Intuition: the pooling layer asks whether a feature is anywhere in the image and throws away the positional information. Once a feature has been found, you only need its position relative other features, not its exact position.\n",
    "\n",
    "![](http://neuralnetworksanddeeplearning.com/images/tikz48.png)\n",
    "\n",
    "- Example: **L2 Pooling** layers take the square root of the sum of squares of each input segment.\n",
    "\n",
    "### Putting it together\n",
    "\n",
    "![](http://neuralnetworksanddeeplearning.com/images/tikz49.png)\n",
    "\n",
    "1. 28 x 28 input neurons.\n",
    "2. 3 feature maps, each taking 5 x 5 local receptive fields to form a 3 x 24 x 24 convolutional layer.\n",
    "3. 3 max-pooling maps, each taking 2 x 2 local recpetive fields from the convolutional layer to form a 3 x 12 x 12 pooling layer.\n",
    "4. Fully connected output layer.\n",
    "\n",
    "\n",
    "### Backpropagation modifications\n",
    "\n",
    "- The derivation of backpropagation requires some modifications due to the non-fully-connected layers.\n",
    "\n",
    "## Convolutional neural networks in practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction=0.8\n",
    "set_session(tf.Session(config=config))\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 training\n",
      "10000 testing\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/60\n",
      "60000/60000 [==============================] - 12s - loss: 0.4111 - acc: 0.8804 - val_loss: 0.2364 - val_acc: 0.9320\n",
      "Epoch 2/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.2086 - acc: 0.9387 - val_loss: 0.1740 - val_acc: 0.9486\n",
      "Epoch 3/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.1566 - acc: 0.9544 - val_loss: 0.1391 - val_acc: 0.9596\n",
      "Epoch 4/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.1254 - acc: 0.9630 - val_loss: 0.1219 - val_acc: 0.9639\n",
      "Epoch 5/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.1057 - acc: 0.9692 - val_loss: 0.1039 - val_acc: 0.9682\n",
      "Epoch 6/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0904 - acc: 0.9739 - val_loss: 0.0997 - val_acc: 0.9704\n",
      "Epoch 7/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0789 - acc: 0.9774 - val_loss: 0.0971 - val_acc: 0.9699\n",
      "Epoch 8/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0693 - acc: 0.9799 - val_loss: 0.0879 - val_acc: 0.9718\n",
      "Epoch 9/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0622 - acc: 0.9819 - val_loss: 0.0832 - val_acc: 0.9741\n",
      "Epoch 10/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0559 - acc: 0.9843 - val_loss: 0.0799 - val_acc: 0.9752\n",
      "Epoch 11/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0505 - acc: 0.9860 - val_loss: 0.0759 - val_acc: 0.9773\n",
      "Epoch 12/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0453 - acc: 0.9875 - val_loss: 0.0753 - val_acc: 0.9758\n",
      "Epoch 13/60\n",
      "60000/60000 [==============================] - 12s - loss: 0.0414 - acc: 0.9890 - val_loss: 0.0737 - val_acc: 0.9768\n",
      "Epoch 14/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0377 - acc: 0.9901 - val_loss: 0.0797 - val_acc: 0.9759\n",
      "Epoch 15/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0348 - acc: 0.9910 - val_loss: 0.0709 - val_acc: 0.9780\n",
      "Epoch 16/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0315 - acc: 0.9921 - val_loss: 0.0733 - val_acc: 0.9768\n",
      "Epoch 17/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0289 - acc: 0.9931 - val_loss: 0.0709 - val_acc: 0.9772\n",
      "Epoch 18/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0268 - acc: 0.9938 - val_loss: 0.0706 - val_acc: 0.9778\n",
      "Epoch 19/60\n",
      "60000/60000 [==============================] - 12s - loss: 0.0241 - acc: 0.9950 - val_loss: 0.0681 - val_acc: 0.9789\n",
      "Epoch 20/60\n",
      "60000/60000 [==============================] - 12s - loss: 0.0223 - acc: 0.9956 - val_loss: 0.0711 - val_acc: 0.9778\n",
      "Epoch 21/60\n",
      "60000/60000 [==============================] - 13s - loss: 0.0207 - acc: 0.9958 - val_loss: 0.0677 - val_acc: 0.9790\n",
      "Epoch 22/60\n",
      "60000/60000 [==============================] - 12s - loss: 0.0190 - acc: 0.9965 - val_loss: 0.0692 - val_acc: 0.9788\n",
      "Epoch 23/60\n",
      "60000/60000 [==============================] - 12s - loss: 0.0174 - acc: 0.9972 - val_loss: 0.0712 - val_acc: 0.9780\n",
      "Epoch 24/60\n",
      "60000/60000 [==============================] - 12s - loss: 0.0162 - acc: 0.9976 - val_loss: 0.0700 - val_acc: 0.9782\n",
      "Epoch 25/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0150 - acc: 0.9979 - val_loss: 0.0684 - val_acc: 0.9788\n",
      "Epoch 26/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0141 - acc: 0.9981 - val_loss: 0.0685 - val_acc: 0.9792\n",
      "Epoch 27/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0131 - acc: 0.9984 - val_loss: 0.0705 - val_acc: 0.9779\n",
      "Epoch 28/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0123 - acc: 0.9987 - val_loss: 0.0705 - val_acc: 0.9788\n",
      "Epoch 29/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0113 - acc: 0.9990 - val_loss: 0.0701 - val_acc: 0.9793\n",
      "Epoch 30/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0107 - acc: 0.9990 - val_loss: 0.0685 - val_acc: 0.9790\n",
      "Epoch 31/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0100 - acc: 0.9991 - val_loss: 0.0692 - val_acc: 0.9786\n",
      "Epoch 32/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0094 - acc: 0.9993 - val_loss: 0.0713 - val_acc: 0.9785\n",
      "Epoch 33/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0090 - acc: 0.9994 - val_loss: 0.0707 - val_acc: 0.9792\n",
      "Epoch 34/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0084 - acc: 0.9995 - val_loss: 0.0689 - val_acc: 0.9794\n",
      "Epoch 35/60\n",
      "60000/60000 [==============================] - 12s - loss: 0.0080 - acc: 0.9996 - val_loss: 0.0703 - val_acc: 0.9788\n",
      "Epoch 36/60\n",
      "60000/60000 [==============================] - 12s - loss: 0.0075 - acc: 0.9996 - val_loss: 0.0709 - val_acc: 0.9792\n",
      "Epoch 37/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0071 - acc: 0.9997 - val_loss: 0.0700 - val_acc: 0.9792\n",
      "Epoch 38/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0067 - acc: 0.9997 - val_loss: 0.0711 - val_acc: 0.9785\n",
      "Epoch 39/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0065 - acc: 0.9998 - val_loss: 0.0716 - val_acc: 0.9785\n",
      "Epoch 40/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0061 - acc: 0.9998 - val_loss: 0.0718 - val_acc: 0.9787\n",
      "Epoch 41/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0059 - acc: 0.9998 - val_loss: 0.0728 - val_acc: 0.9789\n",
      "Epoch 42/60\n",
      "60000/60000 [==============================] - 12s - loss: 0.0055 - acc: 0.9999 - val_loss: 0.0718 - val_acc: 0.9790\n",
      "Epoch 43/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0053 - acc: 0.9999 - val_loss: 0.0723 - val_acc: 0.9788\n",
      "Epoch 44/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0051 - acc: 0.9998 - val_loss: 0.0727 - val_acc: 0.9791\n",
      "Epoch 45/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0049 - acc: 0.9998 - val_loss: 0.0720 - val_acc: 0.9792\n",
      "Epoch 46/60\n",
      "60000/60000 [==============================] - 12s - loss: 0.0047 - acc: 0.9999 - val_loss: 0.0728 - val_acc: 0.9793\n",
      "Epoch 47/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0045 - acc: 0.9999 - val_loss: 0.0738 - val_acc: 0.9791\n",
      "Epoch 48/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0044 - acc: 0.9999 - val_loss: 0.0732 - val_acc: 0.9789\n",
      "Epoch 49/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0042 - acc: 0.9999 - val_loss: 0.0731 - val_acc: 0.9789\n",
      "Epoch 50/60\n",
      "60000/60000 [==============================] - 12s - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0731 - val_acc: 0.9793\n",
      "Epoch 51/60\n",
      "60000/60000 [==============================] - 12s - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0731 - val_acc: 0.9797\n",
      "Epoch 52/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0038 - acc: 0.9999 - val_loss: 0.0732 - val_acc: 0.9792\n",
      "Epoch 53/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0741 - val_acc: 0.9787\n",
      "Epoch 54/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0734 - val_acc: 0.9792\n",
      "Epoch 55/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0748 - val_acc: 0.9789\n",
      "Epoch 56/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0741 - val_acc: 0.9792\n",
      "Epoch 57/60\n",
      "60000/60000 [==============================] - 12s - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0750 - val_acc: 0.9788\n",
      "Epoch 58/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0744 - val_acc: 0.9791\n",
      "Epoch 59/60\n",
      "60000/60000 [==============================] - 12s - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0747 - val_acc: 0.9795\n",
      "Epoch 60/60\n",
      "60000/60000 [==============================] - 11s - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0752 - val_acc: 0.9792\n",
      "holdout accuracy 0.9792\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAFkCAYAAACq4KjhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyiRmYmDoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f717e241450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Baseline: single hidden layer w/ 100 neurons, 60 epochs, learning rate \n",
    "# 0.1, batch size 10, no regularization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "\n",
    "batch_size = 10\n",
    "nb_train = 60000\n",
    "nb_test = 10000\n",
    "nb_pixel = 784\n",
    "nb_classes = 10\n",
    "nb_epochs = 60\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Reshape and scale the images.\n",
    "X_train = X_train.reshape(nb_train, nb_pixel).astype('float32') / 255\n",
    "X_test = X_test.reshape(nb_test, nb_pixel).astype('float32') / 255\n",
    "\n",
    "X_train = X_train[:nb_train]\n",
    "y_train = y_train[:nb_train]\n",
    "\n",
    "print(X_train.shape[0], 'training')\n",
    "print(X_test.shape[0], 'testing')\n",
    "\n",
    "# Convert class labels e.g. '3' to binary class matrices e.g. [0 0 0 1 0 ..].\n",
    "y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_shape=(nb_pixel,), activation='sigmoid', init='normal'))\n",
    "model.add(Dense(10, input_shape=(nb_pixel,), activation='softmax', init='normal'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.1), metrics=['accuracy'])\n",
    "result = model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epochs,\n",
    "                  verbose=1, validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('holdout accuracy', score[1])\n",
    "\n",
    "plt.plot(result.history['acc'], label='Accuracy')\n",
    "plt.plot(result.history['val_acc'], label='Validation Accuracy')\n",
    "plt.plot(result.history['loss'], label='Cost')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test a convolutional network to see if there are better results.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "\n",
    "batch_size = 10\n",
    "nb_train = 60000\n",
    "nb_test = 10000\n",
    "nb_pixel = 784\n",
    "nb_classes = 10\n",
    "nb_epochs = 60\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Reshape and scale the images.\n",
    "X_train = X_train.reshape(nb_train, nb_pixel).astype('float32') / 255\n",
    "X_test = X_test.reshape(nb_test, nb_pixel).astype('float32') / 255\n",
    "\n",
    "X_train = X_train[:nb_train]\n",
    "y_train = y_train[:nb_train]\n",
    "\n",
    "print(X_train.shape[0], 'training')\n",
    "print(X_test.shape[0], 'testing')\n",
    "\n",
    "# Convolutional setup.\n",
    "img_rows, img_cols = 28, 28\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "# Convert class labels e.g. '3' to binary class matrices e.g. [0 0 0 1 0 ..].\n",
    "y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(\n",
    "        nb_filter=24, # Number of kernels (units) in this conv layer.\n",
    "        filter_length=3, # Number of mappings in this conv layer.\n",
    "        input_shape=input_shape)) # Image input shape.\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) # Mapping each 2x2 region in the convolution layer\n",
    "                                         # to a kernel in the pooling layer.\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.1), metrics=['accuracy'])\n",
    "result = model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epochs,\n",
    "                  verbose=1, validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('holdout accuracy', score[1])\n",
    "\n",
    "plt.plot(result.history['acc'], label='Accuracy')\n",
    "plt.plot(result.history['val_acc'], label='Validation Accuracy')\n",
    "plt.plot(result.history['loss'], label='Cost')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
