{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Think Bayes: Chapter 11\n",
    "\n",
    "This notebook presents code and exercises from Think Bayes, second edition.\n",
    "\n",
    "Copyright 2016 Allen B. Downey\n",
    "\n",
    "MIT License: https://opensource.org/licenses/MIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Done'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from collections import Counter\n",
    "from itertools import product\n",
    "from IPython.display import display\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import mythinkbayes as mtb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pdb\n",
    "\n",
    "'Done'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisiting the Euro Problem\n",
    "\n",
    "```\n",
    "A statistical statement appeared in \"The Guardian\" on Friday January 4. 2002:\n",
    "\n",
    "When spun on edge 250 times, a Belgian one-euro coin came up heads 140 times and tails 110. \"It looks very suspicious to me,\" said Barry Blight, a statistics lecturer at the London School of Economics. \"If the coin were unbiased, the chance of getting a result as extreme as that would be less than 7%.\"\n",
    "\n",
    "But do these data give evidence that the coin is biased rather than fair?\n",
    "```\n",
    "\n",
    "### What does it mean to have data in favor of a hypothesis?\n",
    "\n",
    "In chapter 4, Downey proposes that *data are in favor of a hypothesis* if the Bayes factor is greater than 1. \n",
    "\n",
    "Reviewing the Bayes factor and its role for determining if data give evidence:\n",
    "\n",
    "Bayes theorem in probability form:\n",
    "\n",
    "$P(H | D) = \\frac{P(H)P(D|H)}{P(D)}$\n",
    "\n",
    "For two hypotheses $A$ and $B$, the ratio of posterior probabilities:\n",
    "\n",
    "$\\frac{P(A | D)}{P(B | D)} = \\frac{P(A)P(D|A)}{P(B)P(D|B)}$, where the normalizing constants $P(D)$ cancel out.\n",
    "\n",
    "Assuming $A$ and $B$ are mutually exclusive and collectively exhaustive, then:\n",
    "\n",
    "$P(B) = 1 - P(A)$, and we can rewrite the ratio of priors and ratio of posteriors as odds:\n",
    "\n",
    "$O(A|D) = O(A)\\frac{P(D|A)}{P(D|B}$, because $O(A) = \\frac{P(A)}{P(B)}$\n",
    "\n",
    "We might say that data favor a hypothesis if the hypothesis is more likely in light of the data than it was without the data. In other words, if the odds of the hypothesis with the data are higher than the odds without, then the data gives evidence for the hypothesis. This is expressed:\n",
    "\n",
    "$\\frac{O(A|D)}{O(A)} = \\frac{P(D|A)}{P(D|B)}$, where a result $>1$ indicates that the data $D$ gives evidence for the hypothesis $A$.\n",
    "\n",
    "The term on the right is the **Bayes Factor**.\n",
    "\n",
    "To summarize, **Bayes Factor $> 1$ $\\rightarrow$ data gives evidence for hypothesis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Done'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Euro(mtb.PMF):\n",
    "    \n",
    "    def likelihood(self, data, hypo):\n",
    "        p_heads = (hypo / 100)\n",
    "        p_tails = 1 - p_heads\n",
    "        n_heads, n_tails = data\n",
    "        return p_heads**n_heads * p_tails**n_tails\n",
    "\n",
    "'Done'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The likelihood of the 140 heads and 110 tails for an unbiased coin should be ~5.5e-76.\n",
    "\n",
    "However, this only tells us that the probability of exactly 140 heads and 110 tails is very small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood of the data under 50/50 hypothesis = 5.527147875260445e-76\n"
     ]
    }
   ],
   "source": [
    "euro = Euro()\n",
    "like = euro.likelihood((140, 110), 50)\n",
    "assert np.isclose(5.5 * 10**-76, like)\n",
    "print('Likelihood of the data under 50/50 hypothesis =', like)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the likelihood of an unbiased coin (above), now we need the likelihood of \n",
    "a biased coin to compute the Bayes Factor..\n",
    "\n",
    "$\\frac{P(D | B)}{P(D | F)}$, where $B$ and $F$ are the hypotheses that the coin is biased and fair, respectively.\n",
    "\n",
    "But how do we express $B$?\n",
    "\n",
    "A naiive option is to compute the likelihood of the exact result (140 heads, 110 tails). \n",
    "This yields a high ratio, but it's only useful for this exact result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes factor, using observed data to define biased hypothesis = 6.08\n"
     ]
    }
   ],
   "source": [
    "euro = Euro()\n",
    "PDB = euro.likelihood((140, 110), 100 * 140 / 250)\n",
    "PDF = euro.likelihood((140, 110), 50)\n",
    "factor = round(PDB / PDF, 2)\n",
    "assert factor == 6.08\n",
    "print('Bayes factor, using observed data to define biased hypothesis =', factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using the data to define $B$, we need a way to define $B$ objectively.\n",
    "\n",
    "A better option might be to observe that one side of the coin is more pronounced than the other.\n",
    "You might suspect that this will cause a 60/40 bias in one direction, but you're not sure which.\n",
    "Now $B$ consists of two sub-hypotheses, $B_1$ defines a 60/40 bias for heads, $B_2$ defines a 60/40\n",
    "bias for tails. When computing the likelihood, you take their average to get $B$:\n",
    "\n",
    "$P(D|B) = 0.5 \\times (P(D|B_1) + P(D|B_2))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes factor, using two sub-hypotheses to define biased hypothesis = 1.33\n"
     ]
    }
   ],
   "source": [
    "euro = Euro()\n",
    "PDB1 = euro.likelihood((140, 110), 40)\n",
    "PDB2 = euro.likelihood((140, 110), 60)\n",
    "PDF = euro.likelihood((140, 110), 50)\n",
    "factor = round((PDB1 + PDB2) / 2 / PDF, 2)\n",
    "assert factor == 1.33\n",
    "print('Bayes factor, using two sub-hypotheses to define biased hypothesis =', factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generalize the above approach, we can use a uniform-prior PMF of possible bias values \n",
    "and average their likelihoods. \n",
    "\n",
    "This yields a small Bayes Factor, about 0.47."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes factor, where biased hypothesis is an average over biases = 0.47\n"
     ]
    }
   ],
   "source": [
    "euro = Euro()\n",
    "biases = mtb.PMF(range(101))\n",
    "biases[50] = 0\n",
    "biases.normalize()\n",
    "\n",
    "PDB = sum([euro.likelihood((140, 110), hypo) * prob for hypo, prob in biases.items()])\n",
    "PDF = euro.likelihood((140, 110), 50)\n",
    "factor = round(PDB / PDF, 2)\n",
    "assert factor == 0.47\n",
    "print('Bayes factor, where biased hypothesis is an average over biases =', factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now replace the uniform prior for biases with a triangular prior and re-compute the Bayes factor with the same formulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes factor, where biased hypotheses is an average over biases with a triangular prior = 0.84\n"
     ]
    }
   ],
   "source": [
    "euro = Euro()\n",
    "\n",
    "X = np.arange(0, 101)\n",
    "m = np.median(X)\n",
    "P = np.abs(X - m) - m\n",
    "biases = mtb.PMF(X, P)\n",
    "\n",
    "PDB = sum([euro.likelihood((140, 110), hypo) * prob for hypo, prob in biases.items()])\n",
    "PDF = euro.likelihood((140, 110), 50)\n",
    "factor = round(PDB / PDF, 2)\n",
    "assert factor == 0.84\n",
    "print('Bayes factor, where biased hypotheses is an average over biases with a triangular prior =', factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moral of the Story: it depends what you mean by *biased*\n",
    "\n",
    "> In summary, we can use Bayesian hypothesis testing to compare the likelihood of $F$ and $B$,\n",
    "but we have to do some work to specify precisely what $B$ means. This specification depends on\n",
    "background information about coins and their behavior when spun, so people could reasonably\n",
    "disagree about the right definition."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
