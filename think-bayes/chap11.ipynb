{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Think Bayes: Chapter 11\n",
    "\n",
    "This notebook presents code and exercises from Think Bayes, second edition.\n",
    "\n",
    "Copyright 2016 Allen B. Downey\n",
    "\n",
    "MIT License: https://opensource.org/licenses/MIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Done'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from collections import Counter\n",
    "from itertools import product\n",
    "from IPython.display import display\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import mythinkbayes as mtb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pdb\n",
    "\n",
    "'Done'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisiting the Euro Problem\n",
    "\n",
    "```\n",
    "A statistical statement appeared in \"The Guardian\" on Friday January 4. 2002:\n",
    "\n",
    "When spun on edge 250 times, a Belgian one-euro coin came up heads 140 times and tails 110. \"It looks very suspicious to me,\" said Barry Blight, a statistics lecturer at the London School of Economics. \"If the coin were unbiased, the chance of getting a result as extreme as that would be less than 7%.\"\n",
    "\n",
    "But do these data give evidence that the coin is biased rather than fair?\n",
    "```\n",
    "\n",
    "### What does it mean to have data in favor of a hypothesis?\n",
    "\n",
    "In chapter 4, Downey proposes that *data are in favor of a hypothesis* if the Bayes factor is greater than 1. \n",
    "\n",
    "Reviewing the Bayes factor and its role for determining if data give evidence:\n",
    "\n",
    "Bayes theorem in probability form:\n",
    "\n",
    "$P(H | D) = \\frac{P(H)P(D|H)}{P(D)}$\n",
    "\n",
    "For two hypotheses $A$ and $B$, the ratio of posterior probabilities:\n",
    "\n",
    "$\\frac{P(A | D)}{P(B | D)} = \\frac{P(A)P(D|A)}{P(B)P(D|B)}$, where the normalizing constants $P(D)$ cancel out.\n",
    "\n",
    "Assuming $A$ and $B$ are mutually exclusive and collectively exhaustive, then:\n",
    "\n",
    "$P(B) = 1 - P(A)$, and we can rewrite the ratio of priors and ratio of posteriors as odds:\n",
    "\n",
    "$O(A|D) = O(A)\\frac{P(D|A)}{P(D|B}$, because $O(A) = \\frac{P(A)}{P(B)}$\n",
    "\n",
    "We might say that data favor a hypothesis if the hypothesis is more likely in light of the data than it was without the data. In other words, if the odds of the hypothesis with the data are higher than the odds without, then the data gives evidence for the hypothesis. This is expressed:\n",
    "\n",
    "$\\frac{O(A|D)}{O(A)} = \\frac{P(D|A)}{P(D|B)}$, where a result $>1$ indicates that the data $D$ gives evidence for the hypothesis $A$.\n",
    "\n",
    "The term on the right is the **Bayes Factor**.\n",
    "\n",
    "To summarize, **Bayes Factor $> 1$ $\\rightarrow$ data gives evidence for hypothesis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Done'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Euro(mtb.PMF):\n",
    "    \n",
    "    def likelihood(self, data, hypo):\n",
    "        p_heads = (hypo / 100)\n",
    "        p_tails = 1 - p_heads\n",
    "        n_heads, n_tails = data\n",
    "        return p_heads**n_heads * p_tails**n_tails\n",
    "\n",
    "'Done'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The likelihood of the 140 heads and 110 tails for an unbiased coin should be ~5.5e-76.\n",
    "\n",
    "However, this only tells us that the probability of exactly 140 heads and 110 tails is very small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood of the data under 50/50 hypothesis = 5.527147875260445e-76\n"
     ]
    }
   ],
   "source": [
    "euro = Euro()\n",
    "like = euro.likelihood((140, 110), 50)\n",
    "assert np.isclose(5.5 * 10**-76, like)\n",
    "print('Likelihood of the data under 50/50 hypothesis =', like)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the likelihood of an unbiased coin (above), now we need the likelihood of \n",
    "a biased coin to compute the Bayes Factor..\n",
    "\n",
    "$\\frac{P(D | B)}{P(D | F)}$, where $B$ and $F$ are the hypotheses that the coin is biased and fair, respectively.\n",
    "\n",
    "But how do we express $B$?\n",
    "\n",
    "A naiive option is to compute the likelihood of the exact result (140 heads, 110 tails). \n",
    "This yields a high ratio, but it's only useful for this exact result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes factor, using observed data to define biased hypothesis = 6.08\n"
     ]
    }
   ],
   "source": [
    "euro = Euro()\n",
    "PDB = euro.likelihood((140, 110), 100 * 140 / 250)\n",
    "PDF = euro.likelihood((140, 110), 50)\n",
    "factor = round(PDB / PDF, 2)\n",
    "assert factor == 6.08\n",
    "print('Bayes factor, using observed data to define biased hypothesis =', factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using the data to define $B$, we need a way to define $B$ objectively.\n",
    "\n",
    "A better option might be to observe that one side of the coin is more pronounced than the other.\n",
    "You might suspect that this will cause a 60/40 bias in one direction, but you're not sure which.\n",
    "Now $B$ consists of two sub-hypotheses, $B_1$ defines a 60/40 bias for heads, $B_2$ defines a 60/40\n",
    "bias for tails. When computing the likelihood, you take their average to get $B$:\n",
    "\n",
    "$P(D|B) = 0.5 \\times (P(D|B_1) + P(D|B_2))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes factor, using two sub-hypotheses to define biased hypothesis = 1.33\n"
     ]
    }
   ],
   "source": [
    "euro = Euro()\n",
    "PDB1 = euro.likelihood((140, 110), 40)\n",
    "PDB2 = euro.likelihood((140, 110), 60)\n",
    "PDF = euro.likelihood((140, 110), 50)\n",
    "factor = round((PDB1 + PDB2) / 2 / PDF, 2)\n",
    "assert factor == 1.33\n",
    "print('Bayes factor, using two sub-hypotheses to define biased hypothesis =', factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generalize the above approach, we can use a uniform-prior PMF of possible bias values \n",
    "and average their likelihoods. \n",
    "\n",
    "This yields a small Bayes Factor, about 0.47."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes factor, where biased hypothesis is an average over biases = 0.47\n"
     ]
    }
   ],
   "source": [
    "euro = Euro()\n",
    "biases = mtb.PMF(range(101))\n",
    "biases[50] = 0\n",
    "biases.normalize()\n",
    "\n",
    "PDB = sum([euro.likelihood((140, 110), hypo) * prob for hypo, prob in biases.items()])\n",
    "PDF = euro.likelihood((140, 110), 50)\n",
    "factor = round(PDB / PDF, 2)\n",
    "assert factor == 0.47\n",
    "print('Bayes factor, where biased hypothesis is an average over biases =', factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now replace the uniform prior for biases with a triangular prior and re-compute the Bayes factor with the same formulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes factor, where biased hypotheses is an average over biases with a triangular prior = 0.84\n"
     ]
    }
   ],
   "source": [
    "euro = Euro()\n",
    "\n",
    "X = np.arange(0, 101)\n",
    "m = np.median(X)\n",
    "P = np.abs(X - m) - m\n",
    "biases = mtb.PMF(X, P)\n",
    "\n",
    "PDB = sum([euro.likelihood((140, 110), hypo) * prob for hypo, prob in biases.items()])\n",
    "PDF = euro.likelihood((140, 110), 50)\n",
    "factor = round(PDB / PDF, 2)\n",
    "assert factor == 0.84\n",
    "print('Bayes factor, where biased hypotheses is an average over biases with a triangular prior =', factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moral of the Story: it depends what you mean by *biased*\n",
    "\n",
    "> In summary, we can use Bayesian hypothesis testing to compare the likelihood of $F$ and $B$,\n",
    "but we have to do some work to specify precisely what $B$ means. This specification depends on\n",
    "background information about coins and their behavior when spun, so people could reasonably\n",
    "disagree about the right definition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "**Exercise 11.1:** Some people believe in the existence of extra-sensory perception (ESP); for example,\n",
    "the ability of some people to guess the value of an unseen playing card with probability better than\n",
    "chance.\n",
    "\n",
    "What is your prior degree of belief in this kind of ESP? Do you think it is as likely to exist as not?\n",
    "Or are you more skeptical about it? Write down your prior odds.\n",
    "\n",
    "Now compute the strength of the evidence it would take to convince you that ESP is at least 50% likely\n",
    "to exist. What Bayes factor would be needed to make you 90% sure that ESP exists?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assumptions**\n",
    "\n",
    "Start with two hypotheses $A$ and $B$, for *ESP doesn't exist* and *ESP does exist*, respectively.\n",
    "\n",
    "I think ESP is very unlikely to exist. Let's say that my prior belief $P(B)$ is roughly equivalent to the probability of the same American getting struck by lightning once a year for ten consecutive years. [According to the national weather service](http://www.lightningsafety.noaa.gov/odds.shtml), this probability is $(\\frac{1}{1,083,000})^{10} \\approx 4.5 \\times 10^{-61}$. What an unlucky guy!\n",
    "\n",
    "So $P(B) = 4.5 \\times 10^{-61}$, and consequently $P(A) = 1 - 4.5 \\times 10^{-61}$\n",
    "\n",
    "**Strength of evidence to convince me that ESP is at least 50% likely to exist:**\n",
    "\n",
    "This is equivalent to asking for the strength of evidence such $P(A|D) = P(B|D)$.\n",
    "\n",
    "Starting with the priors defined above, we should find a way to express the likelihood $P(D|B)$ that represents its \"strength\"...\n",
    "\n",
    "$P(B | D) = P(A | D)$\n",
    "\n",
    "$\\rightarrow \\frac{P(D|B)P(B)}{P(D)} = \\frac{P(D|A)P(A)}{P(D)}$\n",
    "\n",
    "$\\rightarrow P(D|B)P(B) = P(D|A)P(A)$\n",
    "\n",
    "$\\rightarrow P(D|B) = \\frac{P(A)}{P(B)} \\times P(D|A)$\n",
    "\n",
    "$\\rightarrow P(D|B) = O(A) \\times P(D|A)$\n",
    "\n",
    "So the likelihood $P(D|B$ must be $O(A)$ times greater than the likelihood $P(D|A)$.\n",
    "\n",
    "$O(A)$ is HUGE: $O(A) = \\frac{1 - 4.5\\times 10^{-61}}{4.5\\times 10^{-61}} \\approx 2.2 \\times 10^{60}$\n",
    "\n",
    "**What Bayes factor would be needed to make you 90% sure that ESP exists?**\n",
    "\n",
    "This is similar to the previous question, except now we need to express the likelihood $P(D|B)$ to satisfy:\n",
    "\n",
    "$P(B | D) = 9 \\times P(A | D)$\n",
    "\n",
    "$\\rightarrow \\frac{P(D|B)P(B)}{P(D)} = 9 \\times \\frac{P(D|A)P(A)}{P(D)}$\n",
    "\n",
    "$\\rightarrow P(D|B)P(B) = 9 \\times P(D|A)P(A)$\n",
    "\n",
    "$\\rightarrow P(D|B) = 9 \\times \\frac{P(A)}{P(B)} \\times P(D|A)$\n",
    "\n",
    "$\\rightarrow P(D|B) = 9 \\times O(A) \\times P(D|A)$\n",
    "\n",
    "So in this case, $O(A)$ is even HUGER: $O(A) \\approx 1.9 \\times 10^{61}$\n",
    "\n",
    "\n",
    "***Note:*** The exercise asked specifically for a Bayes Factor, but I find it more intuitive to think about the evidence as described above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 11.2:** Suppose that your answer to the previous question is 1000; that is, \n",
    "evidence with Bayes factor 1000 in favor of ESP would be sufficient to change your mind.\n",
    "\n",
    "Now suppose that you read a paper in a respectable peer-reviewed scientific journal that\n",
    "presents evidence with Bayes factor 1000 in favor of ESP. Would that change your mind?\n",
    "\n",
    "If not, how do you resolve the apparent contradiction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would acknowledge that the authors found a particular context in which ESP exists and continue on with my life which consists overwhelmingly of contexts where ESP has not been proven to exist."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
